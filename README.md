ğŸ•µï¸ Truth Weaver â€“ Whispering Shadows Mystery

An AI-powered Digital Detective that listens to deceptive audio testimonies, transcribes them, and extracts the most likely truth by spotting contradictions and unreliable claims.

Built for Rendezvous IIT Delhi Hackathon â€“ Organized by ARIES & Eightfold AI.

ğŸš€ Features

ğŸ™ï¸ Speech-to-Text: Converts audio (via Whisper) into transcripts.

ğŸ§¹ Preprocessing & Postprocessing: Cleans noisy, distorted speech.

ğŸ•µï¸ Truth Analysis: Detects contradictions, inflated claims, and fabrications.

ğŸ“‘ Hackathon-Compliant Outputs:

Transcript file (.txt) per session.

Final structured JSON (.json) with revealed truth & deception patterns.

ğŸŒ Full-Stack App: Flask backend + Next.js frontend with clean UI.

âš¡ Multi-Session Support: Upload up to 5 testimonies per shadow.

ğŸ“‚ Project Structure
voice-to-text-analysis/
â”‚â”€â”€ backend/              # Flask backend
â”‚   â”œâ”€â”€ app.py            # Main API server
â”‚   â”œâ”€â”€ pipeline/         # Processing modules
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â”œâ”€â”€ stt.py        # Whisper STT
â”‚   â”‚   â”œâ”€â”€ postprocess.py
â”‚   â”‚   â”œâ”€â”€ analyze.py    # Truth extraction
â”‚   â”‚   â””â”€â”€ output.py
â”‚   â”œâ”€â”€ transcripts/      # Generated .txt transcripts
â”‚   â”œâ”€â”€ output/           # Generated .json analysis
â”‚   â”œâ”€â”€ requirements.txt  # Python dependencies
â”‚
â”‚â”€â”€ frontend/             # Next.js frontend
â”‚   â”œâ”€â”€ src/app/          # App router
â”‚   â”‚   â””â”€â”€ api/          # API routes (proxy to backend)
â”‚   â”œâ”€â”€ public/           # Static assets
â”‚   â”œâ”€â”€ package.json      # Node dependencies
â”‚
â””â”€â”€ README.md             # You are here

âš™ï¸ Setup Instructions
1ï¸âƒ£ Backend (Flask + Whisper)

Go to backend:

cd backend


Install dependencies:

pip install -r requirements.txt


If Whisper/ffmpeg missing:

pip install openai-whisper torch torchaudio ffmpeg-python
sudo apt-get update && sudo apt-get install -y ffmpeg


Run backend server:

python app.py


Runs on:
ğŸ‘‰ http://localhost:5001

2ï¸âƒ£ Frontend (Next.js)

Go to frontend:

cd frontend


Install dependencies:

npm install


Start dev server:

npm run dev


Runs on:
ğŸ‘‰ http://localhost:3000

3ï¸âƒ£ Upload Audio & Analyze

Open http://localhost:3000

Choose:

ğŸ™ï¸ Record audio live

ğŸ“‚ Upload a single session file

ğŸ“‚ Upload multiple sessions (session_1 â€¦ session_5)

Results shown in UI:

Transcript (cleaned)

Truth Analysis (programming experience, language, leadership, contradictions)

Outputs saved in backend:

backend/transcripts/{shadow_id}_session_X.txt

backend/output/{shadow_id}_analysis.json

ğŸ“‘ Output Format (JSON Schema)
{
  "shadow_id": "string",
  "revealed_truth": {
    "programming_experience": "string",
    "programming_language": "string",
    "skill_mastery": "string",
    "leadership_claims": "string",
    "team_experience": "string",
    "skills and other keywords": ["string", "string"]
  },
  "deception_patterns": [
    {
      "lie_type": "string",
      "contradictory_claims": ["string", "string"]
    }
  ]
}

ğŸ›  Development Notes

Whisper model can be changed in stt.py (tiny, base, small, medium, large).

Default: base (CPU-friendly).

Multi-session analysis merges testimonies to detect contradictions.

Analysis rules are in pipeline/analyze.py.

Extendable with more NLP logic (for advanced truth inference).

ğŸ¯ Hackathon Deliverables

âœ… Transcript files (.txt)

âœ… Final JSON (.json)

âœ… Source code archive (this repo, minus audio/model weights)

âš¡ Bonus: Agentic Flow diagram (AI interviewer decision-making)

ğŸ“¦ Example Requirements (backend/requirements.txt)
flask
flask-cors
openai-whisper
torch
torchaudio
ffmpeg-python

ğŸ‘¨â€ğŸ’» Author

Abhishek Yadav

Built for Whispering Shadows Mystery â€“ IIT Delhi Hackathon